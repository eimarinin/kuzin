# Параллельное суммирование массива с использованием MPI

## 1. Постановка задачи
Программа демонстрирует:
- Последовательное суммирование элементов массива
- Параллельное суммирование с использованием MPI
- Сравнение времени выполнения последовательного и параллельного подходов
- Распределение вычислений между несколькими процессами

## 2. Основные функции и алгоритмы

### Ключевые MPI-функции:
```bash
MPI_Init()          # Инициализация MPI-окружения
MPI_Comm_rank()     # Получение номера текущего процесса
MPI_Comm_size()     # Получение общего количества процессов
MPI_Scatter()       # Распределение данных между процессами
MPI_Reduce()        # Сбор и редукция данных
MPI_Finalize()      # Завершение работы с MPI
```

### Алгоритм работы:
1. Процесс 0 (главный) инициализирует массив случайных чисел
2. Массив разбивается на части и распределяется между процессами
3. Каждый процесс вычисляет сумму своей части
4. Результаты собираются и суммируются на процессе 0
5. Выполняется сравнение с последовательным вычислением

## 3. Ввод/Вывод
### Входные данные:
```
Размер массива: 1,000,000 элементов (можно изменить в коде)
Число процессов: задается при запуске (параметр -n)
```
### Выходные данные:
```
Sequential:  [сумма] (Time: [время] sec)  # Результат последовательного вычисления
MPI_Reduce:  [сумма] (Time: [время] sec)  # Результат параллельного вычисления
Параметр Speedup (ускорение) показывает, во сколько раз параллельная версия программы работает быстрее последовательной
```

### Команды для компиляции и запуска:
```
# Компиляция (Windows + MS-MPI):
g++ -I"C:\Program Files (x86)\Microsoft SDKs\MPI\Include" -L"C:\Program Files (x86)\Microsoft SDKs\MPI\Lib\x64" main.cpp -lmsmpi -o main.exe

# Запуск (4 процесса):
mpiexec -n 4 main.exe
```